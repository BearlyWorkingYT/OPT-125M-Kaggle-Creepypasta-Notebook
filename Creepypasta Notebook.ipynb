{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f74d8143",
   "metadata": {},
   "source": [
    "Generation Cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b20e4a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If running this cell gives you an error. Install torch, pandas and transformers using pip or conda.\n",
    "#It is recommended you use conda for this notebook.\n",
    "import torch\n",
    "import pandas as pd \n",
    "from transformers import Trainer, AutoModelForCausalLM, AutoTokenizer, TrainingArguments\n",
    "\n",
    "#Set to \"CPU\" if your graphics card doesn't have enough VRAM.\n",
    "device = torch.device(\"cuda\")\n",
    "    \n",
    "#Generates outputs.\n",
    "def generate_story(prompt, max_length=512, min_length=512, temperature=0.7):\n",
    "    print(\"Generating: \" + prompt)\n",
    "    \n",
    "    generated = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False).input_ids\n",
    "    sample_outputs = model.generate(generated.to(device), temperature=temperature, do_sample=True, num_return_sequences=5, max_length=max_length, min_length=min_length)\n",
    "    output_texts = []\n",
    "\n",
    "    for i, sample_output in enumerate(sample_outputs): \n",
    "        output_text = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
    "        #print(output_text + \"\\n\")\n",
    "        output_texts.append(output_text)\n",
    "\n",
    "    return output_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c8949b",
   "metadata": {},
   "source": [
    "Loads models. (Run This cell and the cell above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a426bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, OPTForCausalLM\n",
    "\n",
    "#Don't change either of these.\n",
    "model_name = \"BearlyWorkingYT/OPT-125M-Warriors-TPB\"\n",
    "tokenizer_name = \"BearlyWorkingYT/OPT-125M-Warriors-TPB\"\n",
    "\n",
    "model = OPTForCausalLM.from_pretrained(model_name).to(device)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_name, use_fast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8476ef40",
   "metadata": {},
   "source": [
    "Generates story from model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a8ff338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating: </s>Chapter 1.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Chapter 1. Fireheart had been looking forward to this day since he had first been with the Clan. He had been given a life that had been worth all the pain he had felt. He had been given the strength to fight, to fight against the sickness that had taken over the forest. He had lived as a warrior, and he had fought bravely. He had fought bravely to save the Clan from the sickness, to save the Clan from the sickness that had taken over the forest. He had fought bravely to save the Clan from the sickness that had taken over the forest. He had fought bravely to save the',\n",
       " 'Chapter 1. Fireheart looked up at the sky. The sun was already setting, and the clouds were beginning to thin. The forest was still green, and the trees were growing stronger and stronger. But the forest was still barren. The forest was empty. The forest was empty. All the prey was gone. Fireheart felt his heart pound. The forest was empty. He stared at the stars, and his mind raced. The forest was empty. Fireheart felt his heart begin to pound. He could not imagine the forest being empty. He knew that it was empty, and he knew that it was not his fault. He',\n",
       " 'Chapter 1. Fireheart looked at the pale tabby she-cat. “I’m sorry,” he meowed. “I’m sorry too.” He felt his heart pound. “I’m sorry I didn’t see you when I was in the nursery.” He glanced at the pale tabby. “I’m sorry too.” He saw her eyes glint with a new respect in them. “I’m sorry I didn’t see you when I was in the nursery.” She looked up',\n",
       " 'Chapter 1. Fireheart stood in the clearing, his head high and his eyes wide with alarm. He was about to tell Sandstorm about the warrior code when he heard a familiar voice behind him. “Fireheart!” It was Graystripe. “What’s wrong?” He turned and saw that the deputy was crouching beside him, his eyes wide. “I’ve been hunting with you for a while now.” He glanced at the young warrior, who was already crouched beside Graystripe. “Are you okay?” he asked. “',\n",
       " 'Chapter 1. Fireheart felt his fur prickle as he watched the two cats approach the Twoleg nest. “We’ve come to tell you that you should leave,” he meowed. “You’re a traitor to ThunderClan.” He turned to see Graystripe sitting in the shade of the Highrock, his eyes wide. “I’ll leave you to your own.” He turned his back on Fireheart and Graystripe, and he padded over to join them. “I’m going to ask Sandstorm to come with me']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, OPTForCausalLM\n",
    "\n",
    "#Edit this prompt to control generation.\n",
    "prompt = \"</s>Chapter 1.\"\n",
    "\n",
    "#Adjusted temperature to control randomness of generation.\n",
    "generate_story(prompt, max_length=128, min_length=64, temperature=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f396ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
